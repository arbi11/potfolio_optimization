from langchain_community.embeddings.ollama import OllamaEmbeddings

def get_embedding_function():
    embeddings = OllamaEmbeddings(model="nomic-embed-text")  # if completely local
    return embeddings

def get_word_embedding(word):
    embeddings = get_embedding_function()
    word_embedding = embeddings.embed_query(word)  # Use embed_query for single words or queries
    return word_embedding

# Example usage
word = "example"
embedding = get_word_embedding(word)
print(f"Embedding for '{word}': {embedding}")



len(embedding)





from pathlib import Path
notebook_dir = Path('.')
file_path = notebook_dir.absolute().parent / 'data' / 'secrets.txt'

secret_dict = {}
with open(file_path, 'r') as file:
    for line in file:
        line = line.strip()
        if '=' in line:
            key, value = line.split('=', 1)
            key = key.strip()
            value = value.strip().strip('"')
            secret_dict[key] = value

# print(secret_dict)


API_KEY = secret_dict['API_KEY']
API_SECRET = secret_dict['API_SECRET']
BASE_URL = secret_dict['BASE_URL']

ALPACA_CREDS = {
    "API_KEY":API_KEY,
    "API_SECRET":API_SECRET,
    "PAPER" : True
}


from timedelta import Timedelta
from datetime import datetime, date

def get_dates():
    today = date.today()
    three_days_prior = today - Timedelta(days=3)
    return today.strftime('%Y-%m-%d'), three_days_prior.strftime('%Y-%m-%d')


from alpaca_trade_api import REST

api = REST(base_url= BASE_URL, 
           key_id=API_KEY,
           secret_key=API_SECRET
          )





today, three_days_prior = get_dates()
today, three_days_prior


news = api.get_news(symbol = 'SPY',
                    start = three_days_prior,
                    end = today
                   )


len(news)


news[1]


news = [ev.__dict__["_raw"]["headline"] for ev in news]








import requests
from bs4 import BeautifulSoup
from langchain_community.embeddings.ollama import OllamaEmbeddings

def fetch_news(query):
    url = f"https://news.search.yahoo.com/search?p={query}"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Debugging: Print the response text to inspect the HTML structure
    print(soup.prettify())
    
    # Adjust the class name based on the actual HTML structure
    headlines = [a.text for a in soup.find_all('a', {'class': 's-title'})]
    
    # Debugging: Print the fetched headlines
    print(f"Fetched headlines for {query}: {headlines}")
    
    return headlines

def get_embedding_function():
    embeddings = OllamaEmbeddings(model="nomic-embed-text")
    return embeddings

def get_word_embedding(word):
    embeddings = get_embedding_function()
    word_embedding = embeddings.embed_query(word)
    return word_embedding



# Example usage
etfs = ["SPY", "IVV", "VOO", "VTI", "QQQ", "VEA", "VUG", "VTV", "IEFA", "AGG"]
for etf in etfs:
    news_headlines = fetch_news(etf)
    print(news_headlines)
    # for headline in news_headlines:
    #     embedding = get_word_embedding(headline)
    #     print(f"Embedding for '{etf}' in headline '{headline}': {embedding}")



