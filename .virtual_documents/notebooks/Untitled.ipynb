import pandas as pd
from pathlib import Path





p = Path(r"F:\cc_data").resolve()
file_loc = p.absolute() / 'cc_transactions.csv'
print(file_loc)
data = pd.read_csv(file_loc).drop(['Filter', 'Sub-description', 'Status', 'Amount', 'Date'], axis=1)
# dropping these columns as they are not relevant for the task
data.head(2)


data['Description'].nunique()





data['Description'].value_counts()[:2]





from langchain_community.llms import Ollama


llm = Ollama(model="llama3.1:latest")
llm.invoke("Hello, what is 5+10?")





prompt = """Can you add an appropriate category to the my expenses. Example: Spotify AB by Adyen --- Entertainment. 
Make sure you follow the template of three dashes (---) seperating the input expense and your predicted category.
I am located in Toronto, Canada. 
Categories should be less than 5 words. 
Here is the one you need to categorize: """ + unique_transactions[0]
prompt





categories_df_all = pd.DataFrame(columns = ['Transaction vs category', 'Transaction', 'Category'])
for inx, transaction in enumerate(unique_transactions):
    try:
        prompt = """Can you add an appropriate category to the my expenses. Example: Spotify AB by Adyen --- Entertainment. 
        Make sure you follow the template of three dashes (---) seperating the input expense and your predicted category.
        I am located in Toronto, Canada. 
        Categories should be less than 5 words. 
        Here is the one you need to categorize: """ + transaction
        
        response = llm.invoke(prompt)
        response = response.split('\n')
        print(response)
    
        categories_item = pd.DataFrame({'Transaction vs category': response})
        categories_item[['Transaction', 'Category']] = categories_item['Transaction vs category'].str.split('---', expand=True)
        categories_df_all = pd.concat([categories_df_all, categories_item], ignore_index=True)
        break
    except Exception as e:
        print('\nError at : ', inx, transaction)
        print('\t', e, '\n')
        
    





categories_df_all






