import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
import datetime
import yfinance as yf



import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric_temporal.nn.recurrent import A3TGCN2
from torch_geometric_temporal.signal import temporal_signal_split


from pathlib import Path
data_dir = Path(r'F:\cc_data')


# GPU support
DEVICE = torch.device('cpu') # cuda
shuffle=True
batch_size = 32








start = datetime.datetime(2020, 1, 1)
end = datetime.datetime.now()








import yfinance as yf

tickers = ["SPY", "IVV", "VOO", "VTI", "QQQ", "VEA", "VUG", "VTV", "IEFA", "AGG"]

df = yf.download(tickers, start=start, end=end)
df.head()


df.index.min(), df.index.max()


df.columns


df.to_csv(data_dir / 'top10_etf.csv')








df.shape





data_numpy = df.values
data_numpy.shape


arrays = {}
for level in df.columns.levels[1]:
    arrays[level] = df.xs(level, axis=1, level=1).to_numpy()


arrays.keys()


arrays['AGG'].shape


array_list = list(arrays.values())
array_stack = np.stack(array_list, axis=1)

train_input = np.expand_dims(array_stack, axis=-1)

train_target = array_stack[:, :, 0]
train_target = np.expand_dims(train_target, axis=-1)

train_input.shape, train_target.shape








arrays.shape


indices = [(i, i+(num_steps_in + num_steps_out)) for i in range()]

















# train_input = np.array(train_dataset.features) # (27399, 207, 2, 12) --> (, 10, 4, 15)
# train_target = np.array(train_dataset.targets) # (27399, 207, 12) --> (, 10, 15)
train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)
train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)
train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)
train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)









class TemporalGNN(torch.nn.Module):
    def __init__(self, node_features, periods, batch_size):
        super(TemporalGNN, self).__init__()
        # Attention Temporal Graph Convolutional Cell
        self.tgnn = A3TGCN2(in_channels=node_features,  out_channels=32, periods=periods,batch_size=batch_size) # node_features=2, periods=12
        # Equals single-shot prediction
        self.linear = torch.nn.Linear(32, periods)

    def forward(self, x, edge_index):
        """
        x = Node features for T time steps
        edge_index = Graph edge indices
        """
        h = self.tgnn(x, edge_index) # x [b, 207, 2, 12]  returns h [b, 207, 12]
        h = F.relu(h) 
        h = self.linear(h)
        return h

TemporalGNN(node_features=6, periods=1, batch_size=20)








# Create model and optimizers
model = TemporalGNN(node_features=6, periods=1, batch_size=batch_size).to(DEVICE)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_fn = torch.nn.MSELoss()

print('Net\'s state_dict:')
total_param = 0
for param_tensor in model.state_dict():
    print(param_tensor, '\t', model.state_dict()[param_tensor].size())
    total_param += np.prod(model.state_dict()[param_tensor].size())
print('Net\'s total params:', total_param)
#--------------------------------------------------
print('Optimizer\'s state_dict:')
for var_name in optimizer.state_dict():
    print(var_name, '\t', optimizer.state_dict()[var_name])








num_nodes = 10


edge_index = torch.tensor([(i, j) for i in range(num_nodes) for j in range(num_nodes)], dtype=torch.long).t().contiguous()



from torch_geometric_temporal.signal import StaticGraphTemporalSignal

# Create a StaticGraphTemporalSignal object
dataset = StaticGraphTemporalSignal(edge_index=edge_index, edge_weight=None, features=[train_input], targets=[train_target])


for snapshot in dataset:
    print(snapshot.x.shape, snapshot.edge_index.shape)
    break





for snapshot in dataset:
    static_edge_index = snapshot.edge_index.to(DEVICE)
    break;


model.train()

for epoch in range(5001):
    step = 0
    loss_list = []
    for encoder_inputs, labels in train_loader:
        y_hat = model(encoder_inputs, static_edge_index)         # Get model predictions
        loss = loss_fn(y_hat, labels) # Mean squared error #loss = torch.mean((y_hat-labels)**2)  sqrt to change it to rmse
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        step= step+ 1
        loss_list.append(loss.item())
        if step % 100 == 0 :
            print(sum(loss_list)/len(loss_list))
    if epoch % 100 == 0 :
        print("Epoch {} train RMSE: {:.4E}".format(epoch, sum(loss_list)/len(loss_list)))











model.eval()
step = 0
# Store for analysis
total_loss = []
for encoder_inputs, labels in train_loader:
    # Get model predictions
    y_hat = model(encoder_inputs, static_edge_index)
    # Mean squared error
    loss = loss_fn(y_hat, labels)
    total_loss.append(loss.item())
    # Store for analysis below
    #test_labels.append(labels)
    #predictions.append(y_hat)

print("Test MSE: {:.4f}".format(sum(total_loss)/len(total_loss)))





sensor = 9
timestep = 0
preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in y_hat])
labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])
print("Data points:,", preds.shape)



plt.figure(figsize=(20,5))
sns.lineplot(data=preds, label="pred")
sns.lineplot(data=labs, label="true")



