{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10223bf-9084-488b-a453-48c2c06882b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhan147\\Anaconda3\\envs\\trader\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b386e1ac-e277-4a3c-9eb9-f774f79586ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('.').absolute().parent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7c8c4-31be-4e15-9a1e-65e07fff6deb",
   "metadata": {},
   "source": [
    "# Download a hugging face model & make a Ollama modelfile\n",
    "* Download huggingface CLI - [Hugging Face Hub](https://huggingface.co/docs/huggingface_hub/main/en/guides/cli)\n",
    "* Login to Hugging face - `huggingface-cli login --token $HUGGINGFACE_TOKEN`\n",
    "* `huggingface-cli whoami`\n",
    "* Download a llm model - specifically GGUF one - [GGUF model download](https://www.youtube.com/watch?v=7BH4C6-HP14)\n",
    "* Write a `modelfile` : `FROM ./huggingface_models/mistral-7b-instruct-v0.2.Q4_K_M.gguf`\n",
    "* Create a model: `ollama create mistrallite -f mistral_lite_modelfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8180f98-6fdf-499a-8144-b47339e282f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd919f64-e0e7-4011-9edb-51ed0422cd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99992548-62e3-4238-98e3-8126b9157ca7",
   "metadata": {},
   "source": [
    "* First, we have our original data source, the PDFs.\n",
    "* This data is going to be split into small chunks and then transformed into an embedding and stored inside of the vector database.\n",
    "* Then when we want to ask a question, we'll also turn our query into an embedding.\n",
    "* This will let us fetch the most relevant entries from the database.\n",
    "* We can then use those entries together in a prompt and that's how we get our final response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd086d7c-7a01-42b8-9b3b-4b7ddc071243",
   "metadata": {},
   "source": [
    "# Load Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ae46b8-bac4-4df9-b41e-5fbf5b8c958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "\n",
    "DATA_PATH = r'F:\\cc_data\\SB'\n",
    "\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2226e1d4-2de4-43af-b984-745cf9540130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken:  11.895373582839966\n"
     ]
    }
   ],
   "source": [
    "# Create (or update) the data store.\n",
    "start_time = time()\n",
    "\n",
    "documents = load_documents()\n",
    "print('\\n Time taken: ', time() - start_time)\n",
    "# documents[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70859c1-79fb-492a-8785-9a1c7377fba5",
   "metadata": {},
   "source": [
    "* So each document is basically an object containing the text content of each page in the PDF. \n",
    "* It also has some metadata attached, which tells you the page number and the source of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dedeb69-b8a9-4e39-826e-847b3e7b1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Scotiabank  First  Quarter  Press  Release  2024    1  \n",
      " \n",
      "First  Quarter  2024  Earnings  Release  \n",
      " \n",
      "Scotiabank  reports  first  quarter  results  \n",
      " \n",
      "All amounts  are in Canadian  dollars  and  are based  on our unaudited  Interim  Condensed  Consolidated  Financial  Statements  for the quarter  ended  January  31, 2024  and  \n",
      "related  notes  prepared  in accordance  with  International  Financial  Reporting  Standards  (IFRS)  as issued  by the International  Accounting  Standards  Board  (IASB),  unless  \n",
      "otherwise  noted.  Our  complete  First Quarter  2024  Report  to Shareholders,  including  our unaudited  interim  financial  statements  for the period  ended  January  31, 2024,  can \n",
      "also  be found  on the SEDAR+  website  at www.sedarplus.ca  and  on the EDG AR section  of the SEC‚Äôs  website  at www.sec.gov . Supplementary  Financial  Information  is also  \n",
      "available,  together  with  the First  Quarter  2024  Report  to Shareholders  on the Investor  Relations  page  at www.scotiabank.com . \n",
      " \n",
      "First  Quarter  2024  Highlights  on a Reported  Basis   \n",
      "(versus  Q1 2023)  First  Quar ter 2024  Highlights  on an Adjusted  Basis(1)  \n",
      "(versus  Q1 2023)  \n",
      "‚Ä¢ Net income  of $2,199  million,  compared  to $1,758 million  \n",
      "‚Ä¢ Earnings  per share  (diluted)  of $1.68 , compared  to $1.35 \n",
      "‚Ä¢ Return  on equity(2) of 11.8%, compared  to 9.8% ‚Ä¢ Net income  of $2,212  million,  compared  to $2,352 million  \n",
      "‚Ä¢ Earnings  per share  (diluted)  of $1.69 , compared  to $1.84  \n",
      "‚Ä¢ Return  on equity  of 11.9%, compared  to 13.4% \n",
      "TORONTO,  February  27, 2024  ‚Äî The Bank  of Nova  Scotia  (‚ÄúScotiabank‚Äù)  (TSX:  BNS;  NYSE:  BNS)  reported  first quarter  net income  of $2,199 million  \n",
      "compared  to $1,758 million  in the same  period  last year.  Diluted  earnings  per share  (EPS)  were  $1.68 , compared  to $1.35 in the same  period  a year  ago.  \n",
      "Adjusted  net income(1) for the first quarter  was $2,212 million  and diluted  EPS was $1.69, down  from  $1.84 last year.  Adjusted  return  on equity  was 11.9% \n",
      "compared  to 13.4% a year  ago.  \n",
      "‚ÄúThe Bank delivered  solid  earnings  this quarter  driven  by strong  revenue  growth,  margin  expansion  and expense  discipline.  I am encoura ged by the early  \n",
      "progress  against  our strategic  priorities,  and the further  strengthening  of our balance  sheet  metrics,‚Äù  said  Scott  Thomson,  President  and CEO  of \n",
      "Scotiabank .  \n",
      "Canadian  Banking  delivered  adjusted  earnings(1) of $1,096  million  this quarter  as solid  revenue  growth  from  margin  expansion,  continued  deposit  growth  \n",
      "and expense  management  were  partly  offset  by higher  provision  for credit  losses.  \n",
      "International  Banking  generated  adjusted  earnings(1) of $774  million.  The 32%  quarter -over -quarter  earnings  growth  was driven  by double -digit  revenue  \n",
      "growth,  partly  offset  by higher  provision  for credit  losses  and expenses . \n",
      "Global  Wealth  Management  adjusted  earnings(1) were  $377  million.  Higher  mutual  fund  fees  and lower  expenses  contributed  to 13%  earnings  growth  \n",
      "compared  to the prior  quarter . \n",
      "Global  Banking  and Markets  reported  earnings  of $439  million,  up 6% compared  to the prior  quarter.  Results  were  supported  by lower  provision  for credit  \n",
      "losses  and revenue  growth,  partly  offset  by higher  expenses . \n",
      "The Bank  reported  an increased  Common  Equity  Tier 1 (CET1)  capital  ratio(3) of 12.9 %, up from  11.5%  last year.  \n",
      "‚ÄúWe are making  positive  progress  towards  our goal  of delivering  sustainable,  long -term  value  for our shareholders.  With  the release  of our new  strategy  at \n",
      "our Investor  Day in December,  our team  of Scotiabankers  globally  are energized  and focused  on executing  our strategic  priorities,‚Äù  continued  Mr. \n",
      "Thomson . \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(1) Refer  to Non -GAAP  Measures  section  starting  on page  5.  \n",
      "(2) Refer  to page  50 of the Management‚Äôs  Discussion  & Analysis  in the Bank's  First  Quarter  2024  Report  to Shareholders,  available  on www.sedar plus.ca,  for an explanation  of \n",
      "the composition  of the measure.  Such  explanation  is incorporated  by reference  hereto.  \n",
      "(3) The  Q1 2024  regulatory  capital  ratios  are based  on Revised  Basel  III requiremen ts as determined  in accordance  with  OSFI  Guideline  - Capital  Adequacy  Requirements  \n",
      "(November  2023).  The  Q1 2023  regulatory  capital  ratios  were  prepared  in accordance  with  OSFI  Guideline  - Capital  Adequacy  Requirements  (November  2018).  \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Extract the page_content from each document\n",
    "page_contents = [doc.page_content for doc in documents]\n",
    "\n",
    "# If you want to access the page_content of the first document\n",
    "first_page_content = page_contents[0]\n",
    "print(first_page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56917bbc-3e03-47f9-b492-a18b6a36f5be",
   "metadata": {},
   "source": [
    "## Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d778c7d-bba2-4626-85fc-d29de0e4d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbef4073-702a-485f-bb43-6d44c211afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Scotiabank  First  Quarter  Press  Release  2024    1  \n",
      " \n",
      "First  Quarter  2024  Earnings  Release  \n",
      " \n",
      "Scotiabank  reports  first  quarter  results  \n",
      " \n",
      "All amounts  are in Canadian  dollars  and  are based  on our unaudited  Interim  Condensed  Consolidated  Financial  Statements  for the quarter  ended  January  31, 2024  and  \n",
      "related  notes  prepared  in accordance  with  International  Financial  Reporting  Standards  (IFRS)  as issued  by the International  Accounting  Standards  Board  (IASB),  unless  \n",
      "otherwise  noted.  Our  complete  First Quarter  2024  Report  to Shareholders,  including  our unaudited  interim  financial  statements  for the period  ended  January  31, 2024,  can' metadata={'source': 'F:\\\\cc_data\\\\SB\\\\Q124_Quarterly_Press_Release-EN.pdf', 'page': 0}\n",
      "\n",
      " Time taken:  11.88722825050354\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "documents = load_documents()\n",
    "chunks = split_documents(documents)\n",
    "print(chunks[0])\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d5c1a-2008-4344-8081-6bbd97aeee32",
   "metadata": {},
   "source": [
    "## Chuck Ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e3542-d83a-42ee-b82e-153069c2e0be",
   "metadata": {},
   "source": [
    "We'll use the source path, the page number, and then the chunk number of that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c82c87-0c6a-4001-b441-9276176fcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        source = source[source.find('SB') : ]\n",
    "        \n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        \n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9036f7-a926-4515-953f-241fc9c8f188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10f6aa0b-f51d-4a23-bec6-abb61f99a220",
   "metadata": {},
   "source": [
    "# Embedding Functions & VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99b7bc37-32cc-48a6-9f65-939e6f936d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function returns embedding function\n",
    "# used at 2 places - \n",
    "# The first is going to be when we create the database itself. \n",
    "# And the second is when we actually want to query the database\n",
    "\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "# from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "\n",
    "def get_embedding_function():\n",
    "    # embeddings = BedrockEmbeddings(\n",
    "    #     credentials_profile_name=\"default\", region_name=\"us-east-1\"\n",
    "    # )\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # if completely local\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b075799a-7edc-4eaa-b936-d335d543b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma_SB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4299eb-61f7-42e7-8bfa-6fb08ea6b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"üëâ Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"‚úÖ No new documents to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c90c7-ed7e-42b7-8bb3-523359e7836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhan147\\AppData\\Local\\Temp\\ipykernel_3804\\2203180553.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 0\n",
      "üëâ Adding new documents: 278\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "add_to_chroma(chunks)\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709a9db-0cf8-499d-b467-405303eee81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d1ab4-8aff-480c-b4b5-e97871cd575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02acd29-9aff-49da-81c6-09a08f3224cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3903b8-e547-4f9e-b801-08e2f7134cd8",
   "metadata": {},
   "source": [
    "# Running RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d73bc-9948-44f4-9590-0350e6e873cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3bf42-c906-4780-a34e-ddc15a2fcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embedding_function()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB. Gives k most relevant chunks to the query\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "    model = Ollama(model=\"mistrallite:latest\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)\n",
    "    return response_text, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164df30-de3d-480c-9bec-fd856d42ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "query_text = 'What was the net profit of the company?'\n",
    "response_text, results = query_rag(query_text)\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51e4ba-530f-459e-9577-6580539d0f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfb581-6bab-48c0-b7ce-9080d3edd2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e2bd801-d73d-4343-9ad0-8cb4e0d9077b",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ea7924-b988-41fe-b610-9f9efdc0f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PROMPT = \"\"\"\n",
    "Expected Response: {expected_response}\n",
    "Actual Response: {actual_response}\n",
    "---\n",
    "(Answer with 'true' or 'false') Does the actual response match the expected response? \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058957c-2564-49de-8342-18d1d08c962e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec88447e-6498-45fb-a323-f6507b2137d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and_validate(question: str, expected_response: str):\n",
    "    response_text = query_rag(question)\n",
    "    prompt = EVAL_PROMPT.format(\n",
    "        expected_response=expected_response, actual_response=response_text\n",
    "    )\n",
    "\n",
    "    model = Ollama(model=\"mistrallite:latest\")\n",
    "    evaluation_results_str = model.invoke(prompt)\n",
    "    evaluation_results_str_cleaned = evaluation_results_str.strip().lower()\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    if \"true\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Green if it is correct.\n",
    "        print(\"\\033[92m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return True\n",
    "    elif \"false\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Red if it is incorrect.\n",
    "        print(\"\\033[91m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid evaluation result. Cannot determine if 'true' or 'false'.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf4b185e-0bcf-43da-b395-ddf25cc34b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  A player starts with $1,500 in Monopoly.\n",
      "Sources: ['data\\\\monopoly.pdf:0:0', 'data\\\\monopoly.pdf:0:1', 'data\\\\monopoly.pdf:2:0', 'data\\\\monopoly.pdf:1:2', 'data\\\\monopoly.pdf:2:1']\n",
      "\n",
      "Expected Response: $1500\n",
      "Actual Response:  A player starts with $1,500 in Monopoly.\n",
      "---\n",
      "(Answer with 'true' or 'false') Does the actual response match the expected response? \n",
      "\n",
      "\u001b[92mResponse: true. the actual response describes a situation where a player starts the game of monopoly with $1,500, which is equivalent to the expected response of having a starting amount of $1,500.\u001b[0m\n",
      "\n",
      " Time taken:  27.884098768234253\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "assert query_and_validate(\n",
    "    question=\"How much total money does a player start with in Monopoly? (Answer with the number only)\",\n",
    "    expected_response=\"$1500\",\n",
    ")\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "845eb78f-b1ba-4878-b0e4-afb4e16b6b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  The longest continuous train gets a bonus of 10 points.\n",
      "Sources: ['data\\\\ticket_to_ride.pdf:3:3', 'data\\\\ticket_to_ride.pdf:1:3', 'data\\\\ticket_to_ride.pdf:3:2', 'data\\\\ticket_to_ride.pdf:0:1', 'data\\\\ticket_to_ride.pdf:3:1']\n",
      "\n",
      "Expected Response: 10 points\n",
      "Actual Response:  The longest continuous train gets a bonus of 10 points.\n",
      "---\n",
      "(Answer with 'true' or 'false') Does the actual response match the expected response? \n",
      "\n",
      "\u001b[92mResponse: true. in the given context, both the expected and actual responses mean that a bonus of 10 points is given for having the longest continuous train.\u001b[0m\n",
      "\n",
      " Time taken:  24.800504207611084\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "assert query_and_validate(\n",
    "    question=\"How many points does the longest continuous train get in Ticket to Ride? (Answer with the number only)\",\n",
    "    expected_response=\"10 points\",\n",
    ")\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011634f-7ab1-489d-86f4-7eefeea523c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
