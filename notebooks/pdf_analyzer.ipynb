{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65eb6c2-15e7-4dd1-a1b4-6799f6ed9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0b97ff-2068-4b42-b689-9b0e106da3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = Path('.').absolute().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5512fc22-8faf-4170-85c7-3b9191372991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistrallite:latest\")\n",
    "\n",
    "prompt = 'What is the profit firm earned'\n",
    "response_text = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8b2395-1a8a-428e-848b-c1ca8b039358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "# from llama_index.readers.download_loader import download_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2d848d-e52b-4f78-bf4c-05e3c68d935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "def get_embedding_function():\n",
    "    # embeddings = BedrockEmbeddings(\n",
    "    #     credentials_profile_name=\"default\", region_name=\"us-east-1\"\n",
    "    # )\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # if completely local\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac515fc-eadc-4ffe-a47f-899debcf7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken:  24.381906032562256\n"
     ]
    }
   ],
   "source": [
    "# Pinecone - similar to chroma\n",
    "# document is tokenized and loaded into chroma for querying later\n",
    "# This allows you to perform similarity search using similarity metrics \n",
    "# like euclidean distance \n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "loader = PyPDFLoader(r'F:\\cc_data\\annualreport.pdf')\n",
    "# split pages from pdf\n",
    "pages = loader.load_and_split()\n",
    "pages[0]\n",
    "print('\\n Time taken: ', time() - start_time)\n",
    "\n",
    "# load documents int vector database aka chromaDB\n",
    "# store = Chroma.from_documents(pages, collection_name='annual_report')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe181983-d12c-4f4d-880d-0de8424d498b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'F:\\\\cc_data\\\\annualreport.pdf', 'page': 1}, page_content='2022 Annual General Meeting\\nMacquarie Group Limitedâ€™s 2022 AGM will be held at 10:30 am on \\nThursday, 28 July 2022.\\nDetails of the meeting will be sent to shareholders separately.\\nCover image\\nMacquarie manages investments in infrastructure integral to \\nthe US economy. Long Beach Container Terminal is part of the \\ncombined port complex of Los Angeles and Long Beach, the \\nlargest cargo gateway in North America.\\nMacquarie is a global financial \\nservices group operating in \\n33\\xa0markets in asset management, \\nretail and business banking, wealth \\nmanagement, leasing and asset \\nfinancing, market access, commodity \\ntrading, renewables development, \\nspecialist advice, access to capital \\nand principal investment.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6406a47-c3f6-4029-9c1d-62fe9fd81fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        source = source[source.find('annualreport') : ]\n",
    "        \n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        \n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e4e1dc-bb46-4c68-b992-767256b5fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = 'chroma_AnnualReport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1aecf9e-25b2-4be0-be59-58ce070220d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, \n",
    "        embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"ðŸ‘‰ Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"âœ… No new documents to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384379ff-ea34-475e-a6a5-459c0ab6fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhan147\\AppData\\Local\\Temp\\ipykernel_20800\\2271573457.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 0\n",
      "ðŸ‘‰ Adding new documents: 403\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "add_to_chroma(pages)\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e77a5-00c2-40c3-8efd-7177596a5c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e878c12-c4d1-41b0-a3c2-0e1dd95df669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c4de7-4c2e-4b90-95e1-53bfade0c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca45300-e0fc-4773-b767-6ac11d1b3913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81c738-8d98-47c1-b14b-7e74137194de",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2f94c-6c3f-4c87-8478-1201e93953f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embedding_function()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB. Gives k most relevant chunks to the query\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "    model = Ollama(model=\"mistrallite:latest\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)\n",
    "    return response_text, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392a35e-8ee6-4155-8aba-8e5819e64d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "query_text = 'What was the net profit of the company?'\n",
    "response_text, results = query_rag(query_text)\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffad2c5-f924-4bad-9a31-b8703140aaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3a60a-9ec3-4dfd-8924-6f9f86a4f5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465f297-c88a-47d8-92da-0c2e1c954b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa5fee-1092-4bde-9782-7c7db3070091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c676c19-3d06-4c6d-8e84-1d4a381dbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "query_text = 'What initiatives were taken by bank towards sustainability?'\n",
    "query_rag(query_text)\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbe23f-951b-47e9-8675-959d539eb312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e605ea4-b77c-4d4a-8f2d-f08ce6f35398",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "query_text = 'Summarize the financial performance of the bank'\n",
    "query_rag(query_text)\n",
    "\n",
    "print('\\n Time taken: ', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c805b5f-59bb-4c3f-9c4b-ab506f4a5665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e3010-4577-4576-ab71-ba3827a94dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7e258-63a5-4fd9-a19a-df2ecfb0ab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
